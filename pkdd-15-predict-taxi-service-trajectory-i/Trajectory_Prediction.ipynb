{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = pd.read_csv(\"metaData_taxistandsID_name_GPSlocation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df['LENGTH'] = df['POLYLINE'].apply(lambda x: len(json.loads(x)))\n",
    "df = df[df['LENGTH'] > 8]\n",
    "sample = df[df.MISSING_DATA==False].sample(n=10000).copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates = [item for trajectory in list(sample['POLYLINE'].apply(lambda x: json.loads(x))) for item in trajectory]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coordinates = np.array(coordinates)\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.x = X_data\n",
    "        self.y = y_data\n",
    "        self.n_samples = len(y_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = self.x[idx], self.y[idx]\n",
    "        return data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data(trajectory):\n",
    "    trajectory = np.array(json.loads(trajectory))\n",
    "    trajectory = scaler.transform(trajectory)\n",
    "    length = trajectory.shape[0]\n",
    "    data = []\n",
    "    label = []\n",
    "    for i in range(8, length):\n",
    "        data.append(trajectory[i-8:i])\n",
    "        label.append(trajectory[i])\n",
    "    data = np.stack(data, axis=0)\n",
    "    label = np.stack(label, axis=0)\n",
    "    return data, label\n",
    "\n",
    "def prepare_data(data):\n",
    "    results = list(data['POLYLINE'].apply(lambda x: convert_data(x)))\n",
    "    X, y = list(zip(*results))\n",
    "    X = np.concatenate(X, axis=0)\n",
    "    y = np.concatenate(y, axis=0)\n",
    "    X = torch.from_numpy(X).float()\n",
    "    y = torch.from_numpy(y).float()\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_X, train_y), (valid_X, valid_y), (test_X, test_y) = prepare_data(sample[:7000]), prepare_data(sample[7000:8000]), prepare_data(sample[8000:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = CustomDataset(train_X, train_y)\n",
    "valid_set = CustomDataset(valid_X, valid_y)\n",
    "test_set = CustomDataset(test_X, test_y)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=1000, shuffle=True, num_workers=4)\n",
    "valid_loader = DataLoader(valid_set, batch_size=1000, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_set, batch_size=1, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size, num_layers=2, dropout=0.2):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.in2lstm1 = nn.Linear(input_size, hidden_size)\n",
    "        self.lstm1 = nn.LSTM(hidden_size, hidden_size, num_layers=num_layers, bidirectional=False, batch_first=True, dropout=dropout)\n",
    "        \n",
    "        self.in2lstm2 = nn.Linear(input_size, hidden_size)\n",
    "        self.lstm2 = nn.LSTM(hidden_size, hidden_size, num_layers=num_layers, bidirectional=False, batch_first=True, dropout=dropout)\n",
    "        \n",
    "        self.fc0 = nn.Linear(hidden_size, hidden_size*2)\n",
    "        self.fc1 = nn.Linear(hidden_size*2, int(hidden_size/2))\n",
    "        self.fc2 = nn.Linear(int(hidden_size/2), output_size)\n",
    "        \n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        lstm_out1, _ = self.lstm1(self.in2lstm1(x))\n",
    "        lstm_out2, _ = self.lstm2(self.in2lstm2(x))\n",
    "        out = self.tanh(self.fc0(lstm_out1 + lstm_out2))\n",
    "        out = self.tanh(self.fc1(out))\n",
    "        output = self.fc2(out)[:, -1]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Loss: 1.2519536109102774e-06, Valid Loss: 4.0710645043873225e-09\n",
      "Epoch: 2, Train Loss: 2.2558230040885976e-08, Valid Loss: 2.0078584384464194e-09\n",
      "Epoch: 3, Train Loss: 1.2302679622735014e-08, Valid Loss: 1.176501764348359e-09\n",
      "Epoch: 4, Train Loss: 7.905334110546392e-09, Valid Loss: 8.584805545979179e-10\n",
      "Epoch: 5, Train Loss: 5.795697501525865e-09, Valid Loss: 6.245593076528167e-10\n",
      "Epoch: 6, Train Loss: 4.8794509184517666e-09, Valid Loss: 4.238547135173576e-10\n",
      "Epoch: 7, Train Loss: 4.193665038201289e-09, Valid Loss: 2.9650086116816965e-10\n",
      "Epoch: 8, Train Loss: 3.923364332422352e-09, Valid Loss: 3.7653248909919056e-10\n",
      "Epoch: 9, Train Loss: 3.5696005988938853e-09, Valid Loss: 4.3098550668219106e-10\n",
      "Epoch: 10, Train Loss: 3.4494811361582834e-09, Valid Loss: 2.51320924689935e-10\n",
      "Epoch: 11, Train Loss: 3.3752880535757864e-09, Valid Loss: 2.9557667085100546e-10\n",
      "Epoch: 12, Train Loss: 3.1910504430925354e-09, Valid Loss: 2.967395894302172e-10\n",
      "Epoch: 13, Train Loss: 3.4187720789304877e-09, Valid Loss: 1.7341750731247885e-10\n",
      "Epoch: 14, Train Loss: 2.772820360860351e-09, Valid Loss: 3.9101274796848885e-10\n",
      "Epoch: 15, Train Loss: 2.858743627939475e-09, Valid Loss: 2.2750336165699992e-10\n",
      "Epoch: 16, Train Loss: 2.9211721491719802e-09, Valid Loss: 2.989873551996425e-09\n",
      "Epoch: 17, Train Loss: 2.650199770869222e-09, Valid Loss: 1.5469703043891059e-10\n",
      "Epoch: 18, Train Loss: 2.4947166248239226e-09, Valid Loss: 5.665531716658734e-10\n",
      "Epoch: 19, Train Loss: 2.761536871958015e-09, Valid Loss: 1.6992508403745886e-10\n",
      "Epoch: 20, Train Loss: 2.097893936479522e-09, Valid Loss: 9.6095424169107e-11\n",
      "Epoch: 21, Train Loss: 2.4545862272589144e-09, Valid Loss: 1.38093968416797e-10\n",
      "Epoch: 22, Train Loss: 2.1077908068036777e-09, Valid Loss: 8.256794001226808e-11\n",
      "Epoch: 23, Train Loss: 1.995822778553702e-09, Valid Loss: 1.5433475414283749e-10\n",
      "Epoch: 24, Train Loss: 2.048913356588855e-09, Valid Loss: 1.0253069649479585e-10\n",
      "Epoch: 25, Train Loss: 1.820702776285543e-09, Valid Loss: 2.2230487866181646e-10\n",
      "Epoch: 26, Train Loss: 1.9772889762634807e-09, Valid Loss: 6.097416576267278e-11\n",
      "Epoch: 27, Train Loss: 1.6636753337024857e-09, Valid Loss: 2.1046066513008556e-10\n",
      "Epoch: 28, Train Loss: 1.6922415853741769e-09, Valid Loss: 1.499428794886626e-10\n",
      "Epoch: 29, Train Loss: 1.84100123465214e-09, Valid Loss: 2.871294377655431e-10\n",
      "Epoch: 30, Train Loss: 1.6705429300145624e-09, Valid Loss: 3.420351740714978e-10\n",
      "Epoch: 31, Train Loss: 1.3796945166859587e-09, Valid Loss: 8.007833832834877e-11\n",
      "Epoch: 32, Train Loss: 1.4505103775945826e-09, Valid Loss: 5.6486220046281226e-11\n",
      "Epoch: 33, Train Loss: 1.6707827646769147e-09, Valid Loss: 3.570488597688382e-10\n",
      "Epoch: 34, Train Loss: 1.2976341273542858e-09, Valid Loss: 5.889800258955802e-10\n",
      "Epoch: 35, Train Loss: 1.5992433613973844e-09, Valid Loss: 1.2344245578788105e-10\n",
      "Epoch: 36, Train Loss: 1.3161517430262394e-09, Valid Loss: 1.9008632534678328e-10\n",
      "Epoch: 37, Train Loss: 1.3018295177289475e-09, Valid Loss: 4.406173349025266e-11\n",
      "Epoch: 38, Train Loss: 1.348299500932626e-09, Valid Loss: 9.292599224863807e-11\n",
      "Epoch: 39, Train Loss: 1.1666383917372514e-09, Valid Loss: 6.284524818056525e-11\n",
      "Epoch: 40, Train Loss: 1.486650046217619e-09, Valid Loss: 1.972443883460073e-10\n",
      "Epoch: 41, Train Loss: 1.1712120044649054e-09, Valid Loss: 8.593801862843975e-11\n",
      "Epoch: 42, Train Loss: 1.2009372065904244e-09, Valid Loss: 1.1763598081415694e-10\n",
      "Epoch: 43, Train Loss: 1.1048855145645575e-09, Valid Loss: 7.201074754448201e-11\n",
      "Epoch: 44, Train Loss: 1.1678760327527016e-09, Valid Loss: 9.516372824691644e-11\n",
      "Epoch: 45, Train Loss: 1.1928209646043797e-09, Valid Loss: 3.2330777821698575e-10\n",
      "Epoch: 46, Train Loss: 1.4388236431841504e-09, Valid Loss: 4.780563142503525e-11\n",
      "Epoch: 47, Train Loss: 8.700673628254663e-10, Valid Loss: 3.920706507187788e-11\n",
      "Epoch: 48, Train Loss: 1.102560817230369e-09, Valid Loss: 1.3938263009549701e-10\n",
      "Epoch: 49, Train Loss: 1.358659863342382e-09, Valid Loss: 3.3527510197473025e-11\n",
      "Epoch: 50, Train Loss: 7.500410683292103e-10, Valid Loss: 3.854429911598345e-11\n",
      "Epoch: 51, Train Loss: 9.852014574107669e-10, Valid Loss: 9.854059044300811e-11\n",
      "Epoch: 52, Train Loss: 9.968055410354283e-10, Valid Loss: 3.299941124623729e-11\n",
      "Epoch: 53, Train Loss: 9.544310133833279e-10, Valid Loss: 3.0117459300527117e-10\n",
      "Epoch: 54, Train Loss: 9.199702411706312e-10, Valid Loss: 7.329230663799536e-11\n",
      "Epoch: 55, Train Loss: 1.115604589188024e-09, Valid Loss: 6.363681006860134e-11\n",
      "Epoch: 56, Train Loss: 9.428646073388335e-10, Valid Loss: 4.559991856467605e-11\n",
      "Epoch: 57, Train Loss: 8.551641819281031e-10, Valid Loss: 2.437645052850712e-10\n",
      "Epoch: 58, Train Loss: 1.1723494151283375e-09, Valid Loss: 6.85568422795768e-11\n",
      "Epoch: 59, Train Loss: 7.623730280670315e-10, Valid Loss: 3.4839257409657874e-11\n",
      "Epoch: 60, Train Loss: 8.532922051927016e-10, Valid Loss: 2.6732996730061127e-10\n",
      "Epoch: 61, Train Loss: 9.614485016982144e-10, Valid Loss: 5.816410191528121e-11\n",
      "Epoch: 62, Train Loss: 1.3263652473938237e-09, Valid Loss: 4.089829911890774e-11\n",
      "Epoch: 63, Train Loss: 4.41684747556792e-10, Valid Loss: 3.220422547656199e-11\n",
      "Epoch: 64, Train Loss: 7.352117444838768e-10, Valid Loss: 2.8658230633027413e-11\n",
      "Epoch: 65, Train Loss: 9.528961014098058e-10, Valid Loss: 7.373595281023881e-11\n",
      "Epoch: 66, Train Loss: 7.923219829990558e-10, Valid Loss: 2.8026592644891934e-10\n",
      "Epoch: 67, Train Loss: 9.386120256067444e-10, Valid Loss: 3.278213728208357e-11\n",
      "Epoch: 68, Train Loss: 7.811573840399432e-10, Valid Loss: 4.562141941732989e-11\n",
      "Epoch: 69, Train Loss: 7.472034399711446e-10, Valid Loss: 3.422462430080486e-11\n",
      "Epoch: 70, Train Loss: 7.623748627452188e-10, Valid Loss: 4.9234574930778766e-11\n",
      "Epoch: 71, Train Loss: 8.104262866481804e-10, Valid Loss: 2.762191656984214e-10\n",
      "Epoch: 72, Train Loss: 9.379368025292933e-10, Valid Loss: 3.457509103554912e-11\n",
      "Epoch: 73, Train Loss: 7.46402704180582e-10, Valid Loss: 1.623948837732314e-10\n"
     ]
    }
   ],
   "source": [
    "INPUT_SIZE=2\n",
    "OUTPUT_SIZE=2\n",
    "HIDDEN_SIZE=128\n",
    "NUM_LAYERS = 2\n",
    "LEARNING_RATE = 0.0005\n",
    "N_EPOCHS = 100\n",
    "BATCH_SIZE = train_loader.batch_size\n",
    "\n",
    "model = Model(INPUT_SIZE, OUTPUT_SIZE, HIDDEN_SIZE, NUM_LAYERS)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "\n",
    "for epoch in range(1, N_EPOCHS+1):\n",
    "    train_loss_cache = []\n",
    "    valid_loss_cache = []\n",
    "\n",
    "    train_loss = 0\n",
    "    valid_loss = 0\n",
    "    for X, y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        prediction = model(X)\n",
    "        loss = criterion(prediction, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in valid_loader:\n",
    "            prediction = model(X)\n",
    "            loss = criterion(prediction, y)\n",
    "            valid_loss += loss.item()\n",
    "            \n",
    "    train_loss = train_loss/BATCH_SIZE\n",
    "    valid_loss = valid_loss/BATCH_SIZE\n",
    "    \n",
    "    train_loss_cache.append(train_loss)\n",
    "    valid_loss_cache.append(valid_loss)\n",
    "    \n",
    "    print(f'Epoch: {epoch}, Train Loss: {train_loss/BATCH_SIZE}, Valid Loss: {valid_loss/BATCH_SIZE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
